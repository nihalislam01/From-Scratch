{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a Logistic Regression model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionModel:\n",
    "    def __init__(self):\n",
    "        #Holds the value of coefficients\n",
    "        self.theta = []\n",
    "        #Holds the value of predicted labels\n",
    "        self.predicted = []\n",
    "        #Number of rows the dataset has\n",
    "        self.rows = 0\n",
    "        #Learning rate\n",
    "        self.alpha = 0.01\n",
    "        #Actual Labels\n",
    "        self.label = []\n",
    "        #Actual Features (value of the data that will be given)\n",
    "        self.features = []\n",
    "        #Dimension of the input set\n",
    "        self.dimension = 0\n",
    "\n",
    "    def initialize_theta(self, method):\n",
    "        #Value of the Coefficients will be zero initially\n",
    "        if method == 'zeroinitialization': self.theta = [0 for _ in range(self.dimension + 1)]\n",
    "        #Value of the Coefficients will be random\n",
    "        elif method == 'randominitialization': self.theta = [random.uniform(-1, 1) for _ in range(self.dimension + 1)]\n",
    "        #Value of the Coefficients will be normalized random numbers\n",
    "        elif method == 'normalinitialization': self.theta = [random.gauss(0, 1) for _ in range(self.dimension + 1)]\n",
    "\n",
    "    #Splitting Labels from the dataset\n",
    "    def feature_label_split(self, dataset):\n",
    "        features, labels = zip(*[(data[:-1], data[-1]) for data in dataset])\n",
    "        self.features, self.label = list(features), list(labels)\n",
    "\n",
    "    #Linear Equation\n",
    "    def linear_function(self, row):\n",
    "        return sum(self.theta[index] * value for index, value in enumerate(row)) + self.theta[-1]\n",
    "\n",
    "    #Logistic Function\n",
    "    def logistic_function(self, row):\n",
    "        return 1/(1+math.exp(-self.linear_function(row)))\n",
    "\n",
    "    #Predicted value using the continuous coefficients (theta)\n",
    "    def predict(self, features):\n",
    "        self.predicted = [self.logistic_function(row) for row in features]\n",
    "\n",
    "    #Log Loss\n",
    "    def log_loss(self):\n",
    "        log_errors = [(self.label[i]*math.log(self.predicted[i])) + ((1-self.label[i])*math.log(1-self.predicted[i])) for i in range(self.rows)]\n",
    "        return sum(log_errors) / -self.rows\n",
    "\n",
    "    #Accuracy\n",
    "    def accuracy(self, threshold=0.5):\n",
    "        correct_predictions = 0\n",
    "        \n",
    "        for true, pred in zip(self.label, self.predicted):\n",
    "            predicted_class = 1 if pred >= threshold else 0\n",
    "            if predicted_class == true: correct_predictions += 1\n",
    "        \n",
    "        accuracy_value = (correct_predictions / self.rows)\n",
    "        return accuracy_value\n",
    "\n",
    "    #Updating the value of Coefficients (theta)\n",
    "    def gradient_descent(self):\n",
    "        gradients = [0 for _ in range(self.dimension + 1)]\n",
    "\n",
    "        for i in range(self.rows):\n",
    "            error = self.predicted[i] - self.label[i]\n",
    "            for j in range(self.dimension):\n",
    "                gradients[j] += error * self.features[i][j]\n",
    "            gradients[-1] += error\n",
    "\n",
    "        gradients = [g / self.rows for g in gradients]\n",
    "\n",
    "        self.theta = [self.theta[i] - self.alpha * gradients[i] for i in range(self.dimension + 1)]\n",
    "\n",
    "    #Data training session\n",
    "    def fit(self, dataset, learning_rate=1, init_method='zeroinitialization', epochs=1):\n",
    "        self.rows = len(dataset)\n",
    "        self.alpha = learning_rate\n",
    "        self.dimension = len(dataset[0]) - 1\n",
    "        self.feature_label_split(dataset)\n",
    "        self.initialize_theta(init_method)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            self.predict(self.features)\n",
    "            self.gradient_descent()\n",
    "            current_accuracy = self.accuracy()\n",
    "            current_loss = self.log_loss()\n",
    "            print(f'Epoch {epoch + 1}/{epochs}: Accuracy -> {current_accuracy:.4f}, Loss -> {current_loss:.4f}')\n",
    "\n",
    "    def get_predictions(self, threshold=0.5):\n",
    "        return [1 if pred >= threshold else 0 for pred in self.predicted]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building Dataset\n",
    "alpha = 0.0001\n",
    "dataset = [(x1 := random.randint(0, 100), x2 := random.randint(0, 100), 1 if x1 > x2 else 0) for _ in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegressionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: Accuracy -> 0.5180, Loss -> 0.6931\n",
      "Epoch 2/10: Accuracy -> 0.9350, Loss -> 0.6790\n",
      "Epoch 3/10: Accuracy -> 0.9390, Loss -> 0.6654\n",
      "Epoch 4/10: Accuracy -> 0.9400, Loss -> 0.6524\n",
      "Epoch 5/10: Accuracy -> 0.9420, Loss -> 0.6400\n",
      "Epoch 6/10: Accuracy -> 0.9440, Loss -> 0.6281\n",
      "Epoch 7/10: Accuracy -> 0.9480, Loss -> 0.6166\n",
      "Epoch 8/10: Accuracy -> 0.9510, Loss -> 0.6057\n",
      "Epoch 9/10: Accuracy -> 0.9540, Loss -> 0.5952\n",
      "Epoch 10/10: Accuracy -> 0.9560, Loss -> 0.5851\n"
     ]
    }
   ],
   "source": [
    "model.fit(dataset, learning_rate=alpha, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 is greater than 280\n"
     ]
    }
   ],
   "source": [
    "x1 = 500\n",
    "x2 = 280\n",
    "model.predict([(x1, x2)])\n",
    "classes = ['less', 'greater']\n",
    "print(f'{x1} is {classes[model.get_predictions()[0]]} than {x2}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also traditional programming is better to solve this problem rather than using ML"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1 (v3.12.1:2305ca5144, Dec  7 2023, 17:23:38) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f1062708a37074d70712b695aadee582e0b0b9f95f45576b5521424137d05fec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
